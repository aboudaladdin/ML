{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-5lvr1RKHP3"
   },
   "source": [
    "## 0- Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "EbpKK18CHJWz",
    "outputId": "3c685ac3-311c-4440-86f8-3080743daa38"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import  torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary  \n",
    "from sklearn.metrics import accuracy_score\n",
    "torch.__version__\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_obj(obj):\n",
    "    del obj\n",
    "    print(gc.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_9Ery_vPmBq"
   },
   "source": [
    "## 1- Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfpNO_VGPhp9",
    "outputId": "fea8cfe7-c825-4660-88a1-99312b2ff43f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cYInjwmJgZw"
   },
   "source": [
    "## Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "### Karen Simonyan, Andrew Zisserman (2014). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MngF5yIbJoNW"
   },
   "source": [
    "## 2- Building VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbUT-c7lpEPb"
   },
   "source": [
    "* For Convulotions and Pooling \n",
    "> ![1_GTfU21isi-quqPLitFrICg.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Ymj0NXvuiTqG"
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module): \n",
    "    def __init__(self,n_channels=1,n_classes=10):  \n",
    "        super(VGG16,self).__init__()\n",
    "        #-- VGG16-C\n",
    "        #-- in(3,224,224) -normalized images ((R,G,B) - mean(R,G,B))\n",
    "        #-1- C2d(64,3,3) - C2d(64,3,3) - MP(2,2) #--Conv_MaxPool Stack\n",
    "        #-2- C2d(128,3,3) - C2d(128,3,3) - MP(2,2) #--Conv_MaxPool Stack  \n",
    "        #-3- C2d(256,3,3) - C2d(256,3,3) - C2d(256,1,1) - MP(2,2) #--Conv_MaxPool Stack \n",
    "        \n",
    "        #-4- C2d(512,3,3) - C2d(512,3,3) - C2d(512,1,1) - MP(2,2) #--Conv_MaxPool Stack \n",
    "        #-5- C2d(512,3,3) - C2d(512,3,3) - C2d(512,1,1) - MP(2,2) #--Conv_MaxPool Stack \n",
    "        #-6- FC-1(4096) #--FullyConnected\n",
    "        #-7- FC-2(4096) #--FullyConnected\n",
    "        #-8- FC-3(1000) #--Output 1000-Class\n",
    "        \n",
    "        self.C11 = nn.Conv2d(in_channels = 3, out_channels= 64, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.C12 = nn.Conv2d(in_channels = 64, out_channels= 64, kernel_size=(3,3), padding=1, stride=1)\n",
    "\n",
    "        self.C21 = nn.Conv2d(in_channels = 64, out_channels= 128, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.C22 = nn.Conv2d(in_channels = 128, out_channels= 128, kernel_size=(3,3), padding=1, stride=1)\n",
    "\n",
    "        self.C31 = nn.Conv2d(in_channels = 128, out_channels= 256, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.C32 = nn.Conv2d(in_channels = 256, out_channels= 256, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.C33 = nn.Conv2d(in_channels = 256, out_channels= 256, kernel_size=(1,1), padding=0, stride=1)\n",
    "        \n",
    "        self.C41 = nn.Conv2d(in_channels = 256, out_channels= 512, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.C42 = nn.Conv2d(in_channels = 512, out_channels= 512, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.C43 = nn.Conv2d(in_channels = 512, out_channels= 512, kernel_size=(1,1), padding=0, stride=1)\n",
    "\n",
    "        self.C51 = nn.Conv2d(in_channels = 512, out_channels= 512, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.C52 = nn.Conv2d(in_channels = 512, out_channels= 512, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.C53 = nn.Conv2d(in_channels = 512, out_channels= 512, kernel_size=(1,1), padding=0, stride=1)\n",
    "        \n",
    "        #-- classifier\n",
    "        self.FC1 = nn.Linear(in_features=25088,out_features=4096)\n",
    "        self.FC2 = nn.Linear(in_features=4096,out_features=4096)\n",
    "        self.FC3 = nn.Linear(in_features=4096,out_features=1000)\n",
    "\n",
    "#         #-- classifier (adapted to FashionMnist)\n",
    "#         self.FC1 = nn.Linear(in_features=32768,out_features=256)\n",
    "#         self.FC2 = nn.Linear(in_features=256,out_features=10)\n",
    "        \n",
    "        self.MP = nn.MaxPool2d(kernel_size=(2,2), padding=0, stride=2)\n",
    "        #-- ReLU\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.relu(self.C11(x))\n",
    "        h = torch.relu(self.C12(h))\n",
    "        h = self.MP(h)\n",
    "        \n",
    "        h = torch.relu(self.C21(h))\n",
    "        h = torch.relu(self.C22(h))\n",
    "        h = self.MP(h)\n",
    "        \n",
    "        h = torch.relu(self.C31(h))\n",
    "        h = torch.relu(self.C32(h))\n",
    "        h = torch.relu(self.C33(h))\n",
    "        h = self.MP(h)\n",
    "        \n",
    "        h = torch.relu(self.C41(h))\n",
    "        h = torch.relu(self.C42(h))\n",
    "        h = torch.relu(self.C43(h))\n",
    "        h = self.MP(h)\n",
    "        \n",
    "        h = torch.relu(self.C51(h))\n",
    "        h = torch.relu(self.C52(h))\n",
    "        h = torch.relu(self.C53(h))\n",
    "        h = self.MP(h)\n",
    "        \n",
    "        h = h.reshape(h.shape[0],-1) #- flatten\n",
    "        \n",
    "        h = torch.relu(self.FC1(h))\n",
    "        h = torch.relu(self.FC2(h))\n",
    "        h = torch.relu(self.FC3(h))\n",
    "        #h = self.FC2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "#free memory\n",
    "collect_obj(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KhrUI1UMUoE",
    "outputId": "2b95b443-de2b-4695-f70f-e398a0538730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 64, 224, 224]        1,792\n",
      "├─Conv2d: 1-2                            [-1, 64, 224, 224]        36,928\n",
      "├─MaxPool2d: 1-3                         [-1, 64, 112, 112]        --\n",
      "├─Conv2d: 1-4                            [-1, 128, 112, 112]       73,856\n",
      "├─Conv2d: 1-5                            [-1, 128, 112, 112]       147,584\n",
      "├─MaxPool2d: 1-6                         [-1, 128, 56, 56]         --\n",
      "├─Conv2d: 1-7                            [-1, 256, 56, 56]         295,168\n",
      "├─Conv2d: 1-8                            [-1, 256, 56, 56]         590,080\n",
      "├─Conv2d: 1-9                            [-1, 256, 56, 56]         65,792\n",
      "├─MaxPool2d: 1-10                        [-1, 256, 28, 28]         --\n",
      "├─Conv2d: 1-11                           [-1, 512, 28, 28]         1,180,160\n",
      "├─Conv2d: 1-12                           [-1, 512, 28, 28]         2,359,808\n",
      "├─Conv2d: 1-13                           [-1, 512, 28, 28]         262,656\n",
      "├─MaxPool2d: 1-14                        [-1, 512, 14, 14]         --\n",
      "├─Conv2d: 1-15                           [-1, 512, 14, 14]         2,359,808\n",
      "├─Conv2d: 1-16                           [-1, 512, 14, 14]         2,359,808\n",
      "├─Conv2d: 1-17                           [-1, 512, 14, 14]         262,656\n",
      "├─MaxPool2d: 1-18                        [-1, 512, 7, 7]           --\n",
      "├─Linear: 1-19                           [-1, 4096]                102,764,544\n",
      "├─Linear: 1-20                           [-1, 4096]                16,781,312\n",
      "├─Linear: 1-21                           [-1, 1000]                4,097,000\n",
      "==========================================================================================\n",
      "Total params: 133,638,952\n",
      "Trainable params: 133,638,952\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 11.77\n",
      "==========================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 103.43\n",
      "Params size (MB): 509.79\n",
      "Estimated Total Size (MB): 613.80\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "model = VGG16(n_channels = 1, n_classes = 10)\n",
    "x = torch.randn((1,3,224,224))\n",
    "torchsummary.summary(model,x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXyr0MpeQC27"
   },
   "source": [
    "## 3- Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HA05Hkp6QHm7"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "INPUT_SHAPE = 784\n",
    "N_CLASSES = 10\n",
    "LR = 0.01\n",
    "N_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8jd5FnfQUbL"
   },
   "source": [
    "## 4- Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVq6S7a7QXJB"
   },
   "outputs": [],
   "source": [
    "#-- train_data\n",
    "train_data = datasets.MNIST(root='/dataset',train=True,transform=transforms.ToTensor(),download=True)\n",
    "train_loader = DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "#-- test_data\n",
    "test_data = datasets.MNIST(root='/dataset',train=False,transform=transforms.ToTensor(),download=True)\n",
    "test_loader = DataLoader(test_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "N_BATCHES = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5cM9UJzUNfR",
    "outputId": "087ee577-fac2-433c-d866-d46ca4c5a1e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for b,y in train_loader:\n",
    "    print(b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAuuYzugSE44"
   },
   "source": [
    "## 5- Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DniZHC3SVO0",
    "outputId": "1d73e34b-70f4-4a05-f23e-a2e67e717453"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of CNN(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(n_channels = 1, n_classes = N_CLASSES)\n",
    "model = model.to(device)\n",
    "model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmD0n8DfShz2"
   },
   "source": [
    "## 6- Optimizer, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMS733s0Snor"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAwiUBR9TO61"
   },
   "source": [
    "## 7- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEYpssNOTOen",
    "outputId": "a4e1421d-a78b-4395-ab57-d149d13ad72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- epoch : 0 / 1 --\n",
      "\t-- batch_idx : 0 / 938,\t loss : 0.2815 --\n",
      "\t-- batch_idx : 234 / 938,\t loss : 0.20092 --\n",
      "\t-- batch_idx : 468 / 938,\t loss : 0.11007 --\n",
      "\t-- batch_idx : 702 / 938,\t loss : 0.15226 --\n",
      "\t-- batch_idx : 936 / 938,\t loss : 0.28987 --\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    print(f'-- epoch : {epoch} / {N_EPOCHS} --')\n",
    "    for batch_idx, (data,targets) in enumerate(train_loader):\n",
    "        #-- data to cuda\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        #-- correct data shape (,784)\n",
    "        #data = data.reshape(data.shape[0],-1)\n",
    "\n",
    "        #-- forward\n",
    "        h = model(data)\n",
    "        loss = criterion(h,targets)\n",
    "\n",
    "        #-- backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #-- gradient update\n",
    "        optimizer.step()\n",
    "\n",
    "        #-- print progress\n",
    "        if batch_idx % (N_BATCHES//4) == 0:\n",
    "            print(f'\\t-- batch_idx : {batch_idx} / {N_BATCHES},\\t loss : {round(loss.item(),5)} --')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3UkuLGAX7W-"
   },
   "source": [
    "## 8- Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV3SzAH5YD_H"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(dataloader,model):\n",
    "    #--- mode = evaluation\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    #--- no change to our weights\n",
    "    with torch.no_grad():\n",
    "        for data,targets in dataloader:\n",
    "            #-- data to cuda\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            #-- correct data shape (,784)\n",
    "            #data = data.reshape(data.shape[0],-1)\n",
    "\n",
    "            #-- forward\n",
    "            h = model(data) #--logits (real numbers)\n",
    "            y_pred.append(h.max(dim=1)[1].numpy()) #-- max logits => prediction indices (~ Predicted Numbers)\n",
    "            y_true.append(targets.numpy())\n",
    "    acc = accuracy_score(np.concatenate(y_true),np.concatenate(y_pred))\n",
    "    print('Accuracy : ', acc)\n",
    "    \n",
    "    #-- reset mode = train again\n",
    "    model.train()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQo6c3kCfkEL"
   },
   "source": [
    "* Evaluation on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhmnOti9ZuTy",
    "outputId": "ed4043e8-7a25-47d8-c3b5-297ef91391c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9417166666666666\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_model(train_loader,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hp0f1yCcfhYl"
   },
   "source": [
    "* Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoRuvABAfeUz",
    "outputId": "31ee4676-7173-4dee-f430-5544744392c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9439\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(test_loader,model);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch_fScratch_VGG16_Fashion_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
