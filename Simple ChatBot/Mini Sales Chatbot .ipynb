{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a50389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f741047b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac542c0f",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b0a74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json','r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7f4e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tag', 'patterns', 'responses'])\n",
      "Tag : \n",
      "greeting\n",
      "\n",
      "Patterns : \n",
      "['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day']\n",
      "\n",
      "Responses : \n",
      "['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']\n"
     ]
    }
   ],
   "source": [
    "for intent in data['intents']:\n",
    "    print(intent.keys())\n",
    "    print('Tag : ',intent['tag'],'','Patterns : ',intent['patterns'],'','Responses : ',intent['responses'], sep='\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f73940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "##-- parsing data\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        X_train.append(pattern)\n",
    "        y_train.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f316ce71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patterns</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What do you sell?</td>\n",
       "      <td>items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>When do I get my delivery?</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is anyone there?</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Goodbye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Do you know a joke?</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Patterns     label\n",
       "15           What do you sell?     items\n",
       "22  When do I get my delivery?  delivery\n",
       "3             Is anyone there?  greeting\n",
       "8                      Goodbye   goodbye\n",
       "25         Do you know a joke?     funny"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={'Patterns':X_train, 'label':y_train}).sample(frac=1.0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ee887",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "330c8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.load('punkt')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53be627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show :  ['Do', 'you', 'take', 'credit', 'cards']  , Size :  103\n"
     ]
    }
   ],
   "source": [
    "#--- tokens\n",
    "tokens = []\n",
    "null = df['Patterns'].apply(lambda x: tokens.extend(tokenize(x)))\n",
    "print('Show : ', tokens[:5], ' , Size : ',len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f1e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show :  ['do', 'you', 'take', 'credit', 'card']\n"
     ]
    }
   ],
   "source": [
    "#--- stemming & filtering\n",
    "ignore_words = ['?','!','.',',']\n",
    "\n",
    "filtered_tokens = [stem(tok) for tok in tokens if tok not in ignore_words]\n",
    "print('Show : ', filtered_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715d1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {}\n",
    "index_word = {}\n",
    "\n",
    "frequent_tokens = Counter(filtered_tokens).most_common()\n",
    "\n",
    "for idx, (token, _) in enumerate(frequent_tokens) :\n",
    "    word_index[token] = idx + 1\n",
    "    index_word[idx+1] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca4d57b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['you', 'do', 'take', 'how', 'a', 'are', 'thank', 'long', 'doe', 'what', 'joke', 'i', 'deliveri', 'item', 'there', \"'s\", 'tell', 'me', 'credit', 'card', 'ship', 'sell', 'hi', 'hello', 'goodby', 'know', 'when', 'get', 'my', 'see', 'later', 'bye', 'kind', 'of', 'which', 'have', 'can', 'pay', 'with', 'paypal', 'lot', 'hey', 'cash', 'onli', 'good', 'day', 'that', 'help', 'accept', 'mastercard', 'someth', 'funni', 'is', 'anyon'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f5d04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_sentence(word_index, sentence):\n",
    "    bag_of_words = np.zeros((len(word_index)+1,),dtype=np.long)\n",
    "    \n",
    "    tokens = tokenize(sentence)\n",
    "    filtered_tokens = [stem(tok) for tok in tokens if tok not in ignore_words]\n",
    "    \n",
    "    for tok in filtered_tokens:\n",
    "        if tok in word_index.keys():\n",
    "            idx = word_index[tok]\n",
    "            bag_of_words[idx] = 1\n",
    "    return bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6739b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_sentence(word_index,'how are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69616a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_documents(word_index, documents):\n",
    "    bag_docs = []\n",
    "    for sentence in documents:\n",
    "        bag_sentence = bag_of_words_sentence(word_index, sentence)\n",
    "        bag_docs.append(bag_sentence)\n",
    "    return np.array(bag_docs, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d721aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Get X_train by bag of words\n",
    "X_train = bag_documents(word_index, df['Patterns'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b7888a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Get y_train by encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['label'])\n",
    "y_train = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72c36963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26, 55), (26,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69912a0c",
   "metadata": {},
   "source": [
    "## Dataset, Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16bb47f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, X_train,y_train):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.length = len(y_train)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_train[index, :], self.y_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc27735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "train_dataset = ChatbotDataset(X_train,y_train)\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fd93298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]]) tensor([3, 2], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "##-- check train loader\n",
    "for x,y in train_loader:\n",
    "    print(x,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891af792",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9600d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        #-- very simple linear model\n",
    "        self.l1 = nn.Linear(input_size,hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size,output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.l3(out)\n",
    " \n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "933b9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_size = 128\n",
    "n_classes = label_encoder.classes_.shape[0]\n",
    "\n",
    "model = ChatbotModel(input_size= input_size, hidden_size = hidden_size, output_size = n_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd841657",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0709fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "698b20f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/75], Loss: 1.6685\n",
      "Epoch [10/75], Loss: 0.3487\n",
      "Epoch [15/75], Loss: 0.1166\n",
      "Epoch [20/75], Loss: 0.0275\n",
      "Epoch [25/75], Loss: 0.0107\n",
      "Epoch [30/75], Loss: 0.0185\n",
      "Epoch [35/75], Loss: 0.0067\n",
      "Epoch [40/75], Loss: 0.0100\n",
      "Epoch [45/75], Loss: 0.0024\n",
      "Epoch [50/75], Loss: 0.0007\n",
      "Epoch [55/75], Loss: 0.0010\n",
      "Epoch [60/75], Loss: 0.0014\n",
      "Epoch [65/75], Loss: 0.0017\n",
      "Epoch [70/75], Loss: 0.0007\n",
      "Epoch [75/75], Loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 75\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for bag_words, labels in train_loader:\n",
    "        bag_words = bag_words.to(device)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "        \n",
    " \n",
    "        outputs = model(bag_words)  \n",
    " \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    " \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c33819",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54407175",
   "metadata": {},
   "source": [
    "## Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b30872a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "data_to_save = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"hidden_size\": hidden_size,\n",
    "\"output_size\": n_classes,\n",
    "\"all_words\": word_index\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data_to_save, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5c480",
   "metadata": {},
   "source": [
    "## Chat Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f235cdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Lets Chat ---\n",
      "\n",
      "-----------------------------------------------\n",
      "You: hello\n",
      "Robo: Hi there, what can I do for you? \t [confidence:0.9986945986747742]\n",
      "\n",
      "-----------------------------------------------\n",
      "You: what do you sell?\n",
      "Robo: We have coffee and tea \t [confidence:0.9990430474281311]\n",
      "\n",
      "-----------------------------------------------\n",
      "You: how long does it take to deliver?\n",
      "Robo: Delivery takes 2-4 days \t [confidence:0.9972363114356995]\n",
      "\n",
      "-----------------------------------------------\n",
      "You: $!^%@^!#\n",
      "Robo : I'm Sorry Can you give me more details?\n",
      "----!% Confidence :  0.6546845\n",
      "\n",
      "-----------------------------------------------\n",
      "You: XZXCZCWQE\n",
      "Robo : I'm Sorry Can you give me more details?\n",
      "----!% Confidence :  0.6546845\n",
      "\n",
      "-----------------------------------------------\n",
      "You: tell me a joke\n",
      "Robo: What did the buffalo say when his son left for college? Bison. \t [confidence:0.9998366832733154]\n",
      "\n",
      "-----------------------------------------------\n",
      "You: thank you bye\n",
      "Robo: My pleasure \t [confidence:0.918262779712677]\n",
      "\n",
      "-----------------------------------------------\n",
      "You: q\n"
     ]
    }
   ],
   "source": [
    "def chat(model):\n",
    "    model.eval()\n",
    "    print('--- Lets Chat ---')\n",
    "    while True:\n",
    "        print('')\n",
    "        print('-'*47)\n",
    "        sentence = input('You: ')\n",
    "        if sentence in ['quit', 'q']:\n",
    "            break\n",
    "\n",
    "        x = bag_of_words_sentence(word_index, sentence)\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        output = 0\n",
    "        with torch.no_grad():\n",
    "            output = model(x.unsqueeze(0))   \n",
    "        \n",
    "        output = torch.softmax(output.cpu().detach(), dim=1)\n",
    "        \n",
    "        #print('----','Mean : ', output.mean(),'Max : ',output.max(),'Min : ',output.min())\n",
    "        confidence =  (output.max()).numpy()\n",
    "        \n",
    "        if confidence < 0.7:\n",
    "            print('Robo :', \"I'm Sorry Can you give me more details?\")\n",
    "            print('----!%','Confidence : ', confidence)\n",
    "            continue\n",
    "\n",
    "        value, p_class_idx = torch.max(output, dim=1)\n",
    "        #print(value)\n",
    "        tag_class = label_encoder.classes_[p_class_idx]\n",
    "        #print('Robo: ', label_encoder.classes_[p_class_idx])\n",
    "        \n",
    "        for intent in data['intents']:\n",
    "            if intent['tag'] == tag_class:\n",
    "                print('Robo:', np.random.choice(intent['responses']) ,f'\\t [confidence:{confidence}]')\n",
    "                \n",
    "chat(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daba065",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbaf436",
   "metadata": {},
   "source": [
    "# What's Next, (Improvements)\n",
    "    * We need more data & patterns of interest depending on Use Cases, The Data we trained on is very small and limited.\n",
    "    * We can use sequential model because this is a very simple bag of words dependent model\n",
    "    , it cannot analyze context or sequence meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da868d0",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672d299",
   "metadata": {},
   "source": [
    "* This was done following a tutorial by Python Engineer\n",
    "https://www.youtube.com/watch?v=RpWeNzfSUHw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
